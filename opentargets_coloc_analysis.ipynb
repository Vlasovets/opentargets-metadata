{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4440584f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in ./miniconda3/envs/jupyter_env/lib/python3.10/site-packages (21.0.0)\n",
      "Requirement already satisfied: duckdb in ./miniconda3/envs/jupyter_env/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: pandas==2.2.2 in ./miniconda3/envs/jupyter_env/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy==2.0.2 in ./miniconda3/envs/jupyter_env/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./miniconda3/envs/jupyter_env/lib/python3.10/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./miniconda3/envs/jupyter_env/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./miniconda3/envs/jupyter_env/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./miniconda3/envs/jupyter_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pyarrow\n",
    "!pip install duckdb\n",
    "!pip install --upgrade pandas==2.2.2 numpy==2.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbcb4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import json\n",
    "import pyarrow.dataset as ds\n",
    "import json\n",
    "from pathlib import Path\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfcd58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = Path(\"/lustre/groups/itg/shared/referenceData/OpenTargets/\")\n",
    "\n",
    "base_path = main_dir / \"data_version_29_07\"\n",
    "output_path = main_dir / \"temp/01_filtered_parquets\"\n",
    "manifest_path = main_dir / \"temp/columns_manifest.json\"\n",
    "\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with manifest_path.open() as f:\n",
    "    manifest = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c8200a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " colocalisation_coloc available columns: ['leftStudyLocusId', 'rightStudyLocusId', 'chromosome', 'rightStudyType', 'numberColocalisingVariants', 'h0', 'h1', 'h2', 'h3', 'h4', 'colocalisationMethod', 'betaRatioSignAverage']\n",
      "‚úÖ Saved colocalisation_coloc with 38561709 rows and columns: ['leftStudyLocusId', 'rightStudyLocusId', 'chromosome', 'h4']\n",
      " credible_set available columns: ['studyLocusId', 'studyId', 'variantId', 'chromosome', 'position', 'region', 'beta', 'zScore', 'pValueMantissa', 'pValueExponent', 'effectAlleleFrequencyFromSource', 'standardError', 'subStudyDescription', 'qualityControls', 'finemappingMethod', 'credibleSetIndex', 'credibleSetlog10BF', 'purityMeanR2', 'purityMinR2', 'locusStart', 'locusEnd', 'sampleSize', 'ldSet', 'locus', 'confidence', 'studyType', 'isTransQtl']\n",
      "‚úÖ Saved credible_set with 2833758 rows and columns: ['studyLocusId', 'studyId']\n",
      " l2g_prediction available columns: ['studyLocusId', 'geneId', 'score', 'features', 'shapBaseValue']\n",
      "‚úÖ Saved l2g_prediction with 1473532 rows and columns: ['studyLocusId', 'geneId', 'score']\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, columns in manifest.items():\n",
    "    dataset_dir = base_path / dataset_name\n",
    "    try:\n",
    "\n",
    "        if not dataset_dir.exists():\n",
    "            print(f\"‚ö†Ô∏è Directory does not exist: {dataset_dir}\")\n",
    "            continue\n",
    "            \n",
    "        dataset = ds.dataset(\n",
    "            dataset_dir, \n",
    "            format=\"parquet\", \n",
    "            exclude_invalid_files=True\n",
    "        )\n",
    "        \n",
    "        schema = dataset.schema\n",
    "        available_columns = [field.name for field in schema]\n",
    "        print(f\" {dataset_name} available columns: {available_columns}\")\n",
    "        \n",
    "        valid_columns = [col for col in columns if col in available_columns]\n",
    "        missing_columns = [col for col in columns if col not in available_columns]\n",
    "        \n",
    "        if missing_columns:\n",
    "            print(f\"‚ö†Ô∏è {dataset_name} missing columns: {missing_columns}\")\n",
    "        \n",
    "        if valid_columns:\n",
    "            table = dataset.to_table(columns=valid_columns)\n",
    "            output_file = os.path.join(output_path, f\"{dataset_name}.parquet\")\n",
    "            pq.write_table(table, output_file)\n",
    "            print(f\"‚úÖ Saved {dataset_name} with {len(table)} rows and columns: {valid_columns}\")\n",
    "        else:\n",
    "            print(f\"‚ùå No valid columns found for {dataset_name}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to process {dataset_name}: {e}\")\n",
    "\n",
    "print(f\"\\n Processing complete! Filtered datasets saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9b092d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß¨ GWAS-focused analysis\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d6441aa9b84071baec4f8084d262ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GWAS-focused dataset: 100 rows\n",
      "üìä Unique genes: 9\n",
      "üìö Unique GWAS studies: 91\n",
      "\n",
      "üìã Columns: ['leftStudyLocusId', 'rightStudyLocusId', 'chromosome', 'h4', 'studyId', 'targetId', 'l2g_score', 'studyType', 'traitFromSource', 'projectId']\n",
      "\n",
      "üî¨ Top GWAS colocalizations:\n",
      "  chromosome   h4         targetId       studyId  \\\n",
      "0         19  1.0  ENSG00000142252  GCST90446004   \n",
      "1          1  1.0  ENSG00000169174  GCST90445989   \n",
      "2          1  1.0  ENSG00000169174  GCST90445982   \n",
      "3          1  1.0  ENSG00000169174  GCST90269513   \n",
      "4          1  1.0  ENSG00000169174  GCST90446134   \n",
      "\n",
      "                                     traitFromSource  \n",
      "0  Omega-6 Fatty Acids to Polyunsaturated Fatty A...  \n",
      "1  Free Cholesterol to Cholesterol in Medium VLDL...  \n",
      "2  Cholesteryl esters in medium VLDL (UKB data fi...  \n",
      "3  Cholesteryl esters in VLDL (UKB data field 23416)  \n",
      "4  Free cholesterol in very small VLDL (UKB data ...  \n",
      "\n",
      "üíä Final query with drugs:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350462cd76a9436da73050c451fe5e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final dataset: 100 rows\n",
      "\n",
      "üìä Data completeness:\n",
      "  targetId: 100/100 (100.0%)\n",
      "  diseaseId: 100/100 (100.0%)\n",
      "  drugId: 100/100 (100.0%)\n",
      "  diseaseName: 100/100 (100.0%)\n",
      "  traitFromSource: 100/100 (100.0%)\n",
      "\n",
      "üîç DataFrame structure validation:\n",
      "‚úÖ leftStudyLocusId\n",
      "‚úÖ rightStudyLocusId\n",
      "‚úÖ chromosome\n",
      "‚úÖ h4\n",
      "‚úÖ studyId\n",
      "‚úÖ targetId\n",
      "‚úÖ diseaseId\n",
      "‚úÖ drugId\n",
      "‚úÖ diseaseName\n",
      "\n",
      "üëÄ Sample of final DataFrame:\n",
      "  chromosome   h4         targetId  \\\n",
      "0          1  1.0  ENSG00000169174   \n",
      "1          1  1.0  ENSG00000169174   \n",
      "2          1  1.0  ENSG00000169174   \n",
      "3          1  1.0  ENSG00000169174   \n",
      "4          1  1.0  ENSG00000169174   \n",
      "\n",
      "                                     traitFromSource         drugId  \\\n",
      "0   Triglycerides to total lipids ratio in large LDL  CHEMBL2364655   \n",
      "1  Free cholesterol to total lipids in medium VLD...  CHEMBL4594566   \n",
      "2  Total esterified cholesterol levels (UKB data ...  CHEMBL2364655   \n",
      "3                        Linoleic acid (18:2) levels  CHEMBL2364655   \n",
      "4  Total cholesterol levels in chylomicrons and e...  CHEMBL2364655   \n",
      "\n",
      "                    diseaseName  \n",
      "0  Disorder of lipid metabolism  \n",
      "1       Combined hyperlipidemia  \n",
      "2  Disorder of lipid metabolism  \n",
      "3  Disorder of lipid metabolism  \n",
      "4  Disorder of lipid metabolism  \n",
      "\n",
      "üéØ 100 rows have complete drug information!\n",
      "          targetId                                    traitFromSource  \\\n",
      "0  ENSG00000169174   Triglycerides to total lipids ratio in large LDL   \n",
      "1  ENSG00000169174  Free cholesterol to total lipids in medium VLD...   \n",
      "2  ENSG00000169174  Total esterified cholesterol levels (UKB data ...   \n",
      "3  ENSG00000169174                        Linoleic acid (18:2) levels   \n",
      "4  ENSG00000169174  Total cholesterol levels in chylomicrons and e...   \n",
      "\n",
      "          drugId                   diseaseName  \n",
      "0  CHEMBL2364655  Disorder of lipid metabolism  \n",
      "1  CHEMBL4594566       Combined hyperlipidemia  \n",
      "2  CHEMBL2364655  Disorder of lipid metabolism  \n",
      "3  CHEMBL2364655  Disorder of lipid metabolism  \n",
      "4  CHEMBL2364655  Disorder of lipid metabolism  \n",
      "\n",
      "üéâ Analysis complete!\n",
      "üìä Generated 100 gene-drug-disease associations\n",
      "üí° Use df_final for downstream drug repurposing analysis\n"
     ]
    }
   ],
   "source": [
    "def analyze_gwas_colocalizations(output_path: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Analyze GWAS colocalizations and create drug-target-disease associations.\n",
    "    \n",
    "    This function performs a two-step analysis of genetic colocalization data:\n",
    "    1. Identifies high-confidence GWAS colocalizations with gene targets\n",
    "    2. Links these colocalizations to known drugs and diseases\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    output_path : str\n",
    "        Path to directory containing filtered OpenTargets parquet files:\n",
    "        - colocalisation_coloc.parquet\n",
    "        - credible_set.parquet  \n",
    "        - l2g_prediction.parquet\n",
    "        - study.parquet\n",
    "        - known_drug.parquet\n",
    "        - disease.parquet\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple[pd.DataFrame, pd.DataFrame]\n",
    "        - df_gwas: GWAS colocalizations with gene targets\n",
    "        - df_final: Complete dataset with drug-disease associations\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Query filters:\n",
    "    - h4 > 0.8: High-confidence colocalizations only\n",
    "    - studyId LIKE 'GCST%': GWAS Catalog studies only\n",
    "    - Sample size: 10,000 rows for memory efficiency\n",
    "    - Requires non-null gene predictions (l2g.geneId)\n",
    "    \n",
    "    The analysis links:\n",
    "    - Colocalizations ‚Üí Study loci ‚Üí Genes ‚Üí Drugs ‚Üí Diseases\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> df_gwas, df_final = analyze_gwas_colocalizations('/path/to/data')\n",
    "    >>> print(f\"Found {len(df_final)} gene-drug-disease associations\")\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize DuckDB connection\n",
    "    con = duckdb.connect()\n",
    "    \n",
    "    print(\"üß¨ GWAS-focused analysis\")\n",
    "    \n",
    "    # GWAS colocalizations with gene targets\n",
    "    gwas_focused_query = f\"\"\"\n",
    "    SELECT \n",
    "      coloc.leftStudyLocusId,      -- Unique ID for left study locus in colocalization\n",
    "      coloc.rightStudyLocusId,     -- Unique ID for right study locus in colocalization  \n",
    "      coloc.chromosome,            -- Chromosome where colocalization occurs\n",
    "      coloc.h4,                    -- Posterior probability of shared causal variant (0-1)\n",
    "      credible.studyId,            -- GWAS study identifier (e.g., GCST90...)\n",
    "      l2g.geneId AS targetId,      -- Ensembl gene ID predicted to be affected\n",
    "      l2g.score AS l2g_score,      -- Locus-to-gene prediction confidence (0-1)\n",
    "      study.studyType,             -- Type of study (gwas, qtl, etc.)\n",
    "      study.traitFromSource,       -- Human-readable trait description\n",
    "      study.projectId              -- Source project (e.g., FINNGEN, UKB)\n",
    "    FROM (\n",
    "      SELECT * FROM read_parquet('{output_path}/colocalisation_coloc.parquet')\n",
    "      WHERE h4 > 0.8               -- High-confidence colocalizations only\n",
    "      USING SAMPLE 10000 ROWS      -- Memory-efficient sampling\n",
    "    ) coloc\n",
    "    LEFT JOIN read_parquet('{output_path}/credible_set.parquet') credible\n",
    "      ON coloc.leftStudyLocusId = credible.studyLocusId\n",
    "    LEFT JOIN read_parquet('{output_path}/l2g_prediction.parquet') l2g\n",
    "      ON credible.studyLocusId = l2g.studyLocusId\n",
    "    LEFT JOIN read_parquet('{output_path}/study.parquet') study\n",
    "      ON credible.studyId = study.studyId\n",
    "    WHERE l2g.geneId IS NOT NULL   -- Must have gene prediction\n",
    "      AND credible.studyId LIKE 'GCST%'  -- GWAS Catalog studies only\n",
    "    ORDER BY coloc.h4 DESC, l2g.score DESC\n",
    "    LIMIT 100\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        df_gwas = con.execute(gwas_focused_query).df()\n",
    "        print(f\"‚úÖ GWAS-focused dataset: {len(df_gwas)} rows\")\n",
    "        print(f\"üìä Unique genes: {df_gwas['targetId'].nunique()}\")\n",
    "        print(f\"üìö Unique GWAS studies: {df_gwas['studyId'].nunique()}\")\n",
    "        \n",
    "        print(\"\\nüìã Columns:\", df_gwas.columns.tolist())\n",
    "        print(\"\\nüî¨ Top GWAS colocalizations:\")\n",
    "        print(df_gwas[['chromosome', 'h4', 'targetId', 'studyId', 'traitFromSource']].head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå GWAS query failed: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    print(\"\\nüíä Final query with drugs:\")\n",
    "\n",
    "    # Step 2: Add drug and disease information\n",
    "    final_query = f\"\"\"\n",
    "    SELECT \n",
    "      coloc.leftStudyLocusId,       -- Colocalization identifiers\n",
    "      coloc.rightStudyLocusId, \n",
    "      coloc.chromosome,             -- Genomic location\n",
    "      coloc.h4,                     -- Colocalization confidence\n",
    "      credible.studyId,             -- GWAS study ID\n",
    "      l2g.geneId AS targetId,       -- Drug target gene\n",
    "      kd.diseaseId,                 -- Disease ontology ID (e.g., Orphanet_...)\n",
    "      kd.drugId,                    -- ChEMBL drug identifier\n",
    "      d.name AS diseaseName,        -- Human-readable disease name\n",
    "      study.traitFromSource,        -- GWAS trait description\n",
    "      study.studyType,              -- Study type\n",
    "      l2g.score AS l2g_score        -- Gene prediction confidence\n",
    "    FROM (\n",
    "      SELECT * FROM read_parquet('{output_path}/colocalisation_coloc.parquet')\n",
    "      WHERE h4 > 0.8\n",
    "      USING SAMPLE 10000 ROWS\n",
    "    ) coloc\n",
    "    LEFT JOIN read_parquet('{output_path}/credible_set.parquet') credible\n",
    "      ON coloc.leftStudyLocusId = credible.studyLocusId\n",
    "    LEFT JOIN read_parquet('{output_path}/l2g_prediction.parquet') l2g\n",
    "      ON credible.studyLocusId = l2g.studyLocusId\n",
    "    LEFT JOIN read_parquet('{output_path}/study.parquet') study\n",
    "      ON credible.studyId = study.studyId\n",
    "    LEFT JOIN read_parquet('{output_path}/known_drug.parquet') kd\n",
    "      ON l2g.geneId = kd.targetId   -- Link genes to drugs\n",
    "    LEFT JOIN read_parquet('{output_path}/disease.parquet') d\n",
    "      ON kd.diseaseId = d.id        -- Add disease names\n",
    "    WHERE l2g.geneId IS NOT NULL\n",
    "      AND credible.studyId LIKE 'GCST%'\n",
    "    ORDER BY coloc.h4 DESC, l2g.score DESC\n",
    "    LIMIT 100\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df_final = con.execute(final_query).df()\n",
    "        print(f\"‚úÖ Final dataset: {len(df_final)} rows\")\n",
    "        \n",
    "        # Data quality assessment\n",
    "        print(\"\\nüìä Data completeness:\")\n",
    "        key_columns = ['targetId', 'diseaseId', 'drugId', 'diseaseName', 'traitFromSource']\n",
    "        for col in key_columns:\n",
    "            if col in df_final.columns:\n",
    "                non_null = df_final[col].notna().sum()\n",
    "                print(f\"  {col}: {non_null}/{len(df_final)} ({non_null/len(df_final)*100:.1f}%)\")\n",
    "        \n",
    "        # Validate expected schema\n",
    "        print(\"\\nüîç DataFrame structure validation:\")\n",
    "        desired_columns = ['leftStudyLocusId', 'rightStudyLocusId', 'chromosome', 'h4', \n",
    "                          'studyId', 'targetId', 'diseaseId', 'drugId', 'diseaseName']\n",
    "        \n",
    "        for col in desired_columns:\n",
    "            if col in df_final.columns:\n",
    "                print(f\"‚úÖ {col}\")\n",
    "            else:\n",
    "                print(f\"‚ùå {col} (missing)\")\n",
    "        \n",
    "        # Preview results\n",
    "        print(\"\\nüëÄ Sample of final DataFrame:\")\n",
    "        preview_cols = ['chromosome', 'h4', 'targetId', 'traitFromSource', 'drugId', 'diseaseName']\n",
    "        print(df_final[preview_cols].head())\n",
    "        \n",
    "        # Highlight actionable results\n",
    "        complete_rows = df_final[df_final['drugId'].notna()]\n",
    "        if len(complete_rows) > 0:\n",
    "            print(f\"\\nüéØ {len(complete_rows)} rows have complete drug information!\")\n",
    "            drug_summary_cols = ['targetId', 'traitFromSource', 'drugId', 'diseaseName']\n",
    "            print(complete_rows[drug_summary_cols].head())\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è  No complete drug information in this sample\")\n",
    "        \n",
    "        return df_gwas, df_final\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Final query failed: {e}\")\n",
    "        return df_gwas, None\n",
    "        \n",
    "    finally:\n",
    "        # Clean up database connection\n",
    "        con.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Example usage of the GWAS colocalization analysis.\n",
    "    \n",
    "    This script generates two datasets:\n",
    "    1. High-confidence GWAS colocalizations with gene targets\n",
    "    2. Complete gene-drug-disease association network\n",
    "    \n",
    "    Results can be used for:\n",
    "    - Drug repurposing opportunities\n",
    "    - Target validation\n",
    "    - Precision medicine biomarkers\n",
    "    \"\"\"\n",
    "    \n",
    "    # Run analysis\n",
    "    df_gwas, df_final = analyze_gwas_colocalizations(output_path)\n",
    "    \n",
    "    if df_final is not None:\n",
    "        print(\"\\nüéâ Analysis complete!\")\n",
    "        print(f\"üìä Generated {len(df_final)} gene-drug-disease associations\")\n",
    "        print(\"üí° Use df_final for downstream drug repurposing analysis\")\n",
    "\n",
    "        df_final.to_csv(main_dir / \"colocalisation_drug_association_snapshot.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
